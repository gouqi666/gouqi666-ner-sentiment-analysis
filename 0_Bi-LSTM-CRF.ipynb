{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7528 entries, 0 to 7527\n",
      "Data columns (total 4 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   id        7528 non-null   int64 \n",
      " 1   text      7528 non-null   object\n",
      " 2   BIO_anno  7528 non-null   object\n",
      " 3   class     7528 non-null   int64 \n",
      "dtypes: int64(2), object(2)\n",
      "memory usage: 235.4+ KB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>BIO_anno</th>\n",
       "      <th>class</th>\n",
       "      <th>training_data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>交行14年用过，半年准备提额，却直接被降到1Ｋ，半年期间只T过一次三千，其它全部真实消费，第...</td>\n",
       "      <td>[B-BANK, I-BANK, O, O, O, O, O, O, O, O, O, O,...</td>\n",
       "      <td>0</td>\n",
       "      <td>([交, 行, 1, 4, 年, 用, 过, ，, 半, 年, 准, 备, 提, 额, ，,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>单标我有了，最近visa双标返现活动好</td>\n",
       "      <td>[B-PRODUCT, I-PRODUCT, O, O, O, O, O, O, B-PRO...</td>\n",
       "      <td>1</td>\n",
       "      <td>([单, 标, 我, 有, 了, ，, 最, 近, v, i, s, a, 双, 标, 返,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>建设银行提额很慢的……</td>\n",
       "      <td>[B-BANK, I-BANK, I-BANK, I-BANK, B-COMMENTS_N,...</td>\n",
       "      <td>0</td>\n",
       "      <td>([建, 设, 银, 行, 提, 额, 很, 慢, 的, …, …], [B-BANK, I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>我的怎么显示0.25费率，而且不管分多少期都一样费率，可惜只有69k</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, B-COMMENTS_N, I...</td>\n",
       "      <td>2</td>\n",
       "      <td>([我, 的, 怎, 么, 显, 示, 0, ., 2, 5, 费, 率, ，, 而, 且,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>利率不错，可以撸</td>\n",
       "      <td>[B-COMMENTS_N, I-COMMENTS_N, B-COMMENTS_ADJ, I...</td>\n",
       "      <td>1</td>\n",
       "      <td>([利, 率, 不, 错, ，, 可, 以, 撸], [B-COMMENTS_N, I-CO...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7523</th>\n",
       "      <td>7523</td>\n",
       "      <td>我鼎级拒了</td>\n",
       "      <td>[O, O, O, B-COMMENTS_ADJ, O]</td>\n",
       "      <td>2</td>\n",
       "      <td>([我, 鼎, 级, 拒, 了], [O, O, O, B-COMMENTS_ADJ, O])</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7524</th>\n",
       "      <td>7524</td>\n",
       "      <td>一打一个准，准胜，看激活信用卡时那协议，全是对银行有利的</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, B-COMMENTS_N, I...</td>\n",
       "      <td>2</td>\n",
       "      <td>([一, 打, 一, 个, 准, ，, 准, 胜, ，, 看, 激, 活, 信, 用, 卡,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7525</th>\n",
       "      <td>7525</td>\n",
       "      <td>招行分期白80k</td>\n",
       "      <td>[B-BANK, I-BANK, B-PRODUCT, I-PRODUCT, I-PRODU...</td>\n",
       "      <td>2</td>\n",
       "      <td>([招, 行, 分, 期, 白, 8, 0, k], [B-BANK, I-BANK, B-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7526</th>\n",
       "      <td>7526</td>\n",
       "      <td>5万，额度还行吧没毕业哦</td>\n",
       "      <td>[O, O, O, B-COMMENTS_N, I-COMMENTS_N, O, O, O,...</td>\n",
       "      <td>2</td>\n",
       "      <td>([5, 万, ，, 额, 度, 还, 行, 吧, 没, 毕, 业, 哦], [O, O, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7527</th>\n",
       "      <td>7527</td>\n",
       "      <td>张家港农商、江阴农商、无锡农商试试</td>\n",
       "      <td>[B-BANK, I-BANK, I-BANK, I-BANK, I-BANK, O, B-...</td>\n",
       "      <td>2</td>\n",
       "      <td>([张, 家, 港, 农, 商, 、, 江, 阴, 农, 商, 、, 无, 锡, 农, 商,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7528 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                               text  \\\n",
       "0        0  交行14年用过，半年准备提额，却直接被降到1Ｋ，半年期间只T过一次三千，其它全部真实消费，第...   \n",
       "1        1                                单标我有了，最近visa双标返现活动好   \n",
       "2        2                                        建设银行提额很慢的……   \n",
       "3        3                 我的怎么显示0.25费率，而且不管分多少期都一样费率，可惜只有69k   \n",
       "4        4                                           利率不错，可以撸   \n",
       "...    ...                                                ...   \n",
       "7523  7523                                              我鼎级拒了   \n",
       "7524  7524                       一打一个准，准胜，看激活信用卡时那协议，全是对银行有利的   \n",
       "7525  7525                                           招行分期白80k   \n",
       "7526  7526                                       5万，额度还行吧没毕业哦   \n",
       "7527  7527                                  张家港农商、江阴农商、无锡农商试试   \n",
       "\n",
       "                                               BIO_anno  class  \\\n",
       "0     [B-BANK, I-BANK, O, O, O, O, O, O, O, O, O, O,...      0   \n",
       "1     [B-PRODUCT, I-PRODUCT, O, O, O, O, O, O, B-PRO...      1   \n",
       "2     [B-BANK, I-BANK, I-BANK, I-BANK, B-COMMENTS_N,...      0   \n",
       "3     [O, O, O, O, O, O, O, O, O, O, B-COMMENTS_N, I...      2   \n",
       "4     [B-COMMENTS_N, I-COMMENTS_N, B-COMMENTS_ADJ, I...      1   \n",
       "...                                                 ...    ...   \n",
       "7523                       [O, O, O, B-COMMENTS_ADJ, O]      2   \n",
       "7524  [O, O, O, O, O, O, O, O, O, O, B-COMMENTS_N, I...      2   \n",
       "7525  [B-BANK, I-BANK, B-PRODUCT, I-PRODUCT, I-PRODU...      2   \n",
       "7526  [O, O, O, B-COMMENTS_N, I-COMMENTS_N, O, O, O,...      2   \n",
       "7527  [B-BANK, I-BANK, I-BANK, I-BANK, I-BANK, O, B-...      2   \n",
       "\n",
       "                                          training_data  \n",
       "0     ([交, 行, 1, 4, 年, 用, 过, ，, 半, 年, 准, 备, 提, 额, ，,...  \n",
       "1     ([单, 标, 我, 有, 了, ，, 最, 近, v, i, s, a, 双, 标, 返,...  \n",
       "2     ([建, 设, 银, 行, 提, 额, 很, 慢, 的, …, …], [B-BANK, I...  \n",
       "3     ([我, 的, 怎, 么, 显, 示, 0, ., 2, 5, 费, 率, ，, 而, 且,...  \n",
       "4     ([利, 率, 不, 错, ，, 可, 以, 撸], [B-COMMENTS_N, I-CO...  \n",
       "...                                                 ...  \n",
       "7523    ([我, 鼎, 级, 拒, 了], [O, O, O, B-COMMENTS_ADJ, O])  \n",
       "7524  ([一, 打, 一, 个, 准, ，, 准, 胜, ，, 看, 激, 活, 信, 用, 卡,...  \n",
       "7525  ([招, 行, 分, 期, 白, 8, 0, k], [B-BANK, I-BANK, B-...  \n",
       "7526  ([5, 万, ，, 额, 度, 还, 行, 吧, 没, 毕, 业, 哦], [O, O, ...  \n",
       "7527  ([张, 家, 港, 农, 商, 、, 江, 阴, 农, 商, 、, 无, 锡, 农, 商,...  \n",
       "\n",
       "[7528 rows x 5 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from ast import literal_eval\n",
    "\n",
    "train_data = pd.read_csv('./train_data_public.csv')\n",
    "print(train_data.info())\n",
    "# train_data.drop('Unnamed: 0', axis = 1, inplace = True)\n",
    "test_data = pd.read_csv('./test_public.csv')\n",
    "\n",
    "train_data['BIO_anno'] = train_data['BIO_anno'].apply(lambda x:x.split(' '))\n",
    "train_data['training_data'] = train_data.apply(lambda row: (list(row['text']), row['BIO_anno']), axis = 1)\n",
    "test_data['testing_data'] = test_data.apply(lambda row: (list(row['text'])), axis = 1)\n",
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data_txt = []\n",
    "testing_data_txt = []\n",
    "\n",
    "for i in range(len(train_data)):\n",
    "    training_data_txt.append(train_data.iloc[i]['training_data'])\n",
    "    \n",
    "for i in range(len(test_data)):\n",
    "    testing_data_txt.append(test_data.iloc[i]['testing_data'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bi-LSTM Conditional Random Field\n",
    "### pytorch tutorials https://pytorch.org/tutorials/beginner/nlp/advanced_tutorial.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version:  3.6.10 |Anaconda, Inc.| (default, May  7 2020, 19:46:08) [MSC v.1916 64 bit (AMD64)]\n",
      "Torch version:  1.9.1+cpu\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import torch\n",
    "print(\"Python version:  %s\"%(sys.version))\n",
    "print (\"Torch version:  %s\"%(torch.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x18bfff2dc60>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.autograd as autograd\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 任务1：实体识别"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def argmax(vec):\n",
    "    # return the argmax as a python int\n",
    "    # 返回vec的dim为1维度上的最大值索引\n",
    "    _, idx = torch.max(vec, 1)\n",
    "    return idx.item()\n",
    "\n",
    "def prepare_sequence(seq, to_ix):\n",
    "    # 将句子转化为ID\n",
    "    idxs = [to_ix[w] for w in seq]\n",
    "    return torch.tensor(idxs, dtype=torch.long)\n",
    "\n",
    "\n",
    "# Compute log sum exp in a numerically stable way for the forward algorithm\n",
    "# 前向算法是不断累积之前的结果，这样就会有个缺点\n",
    "# 指数和累积到一定程度后，会超过计算机浮点值的最大值，变成inf，这样取log后也是inf\n",
    "# 为了避免这种情况，用一个合适的值clip去提指数和的公因子，这样就不会使某项变得过大而无法计算\n",
    "# SUM = log(exp(s1)+exp(s2)+...+exp(s100))\n",
    "#     = log{exp(clip)*[exp(s1-clip)+exp(s2-clip)+...+exp(s100-clip)]}\n",
    "#     = clip + log[exp(s1-clip)+exp(s2-clip)+...+exp(s100-clip)]\n",
    "# where clip=max\n",
    "def log_sum_exp(vec):\n",
    "    max_score = vec[0, argmax(vec)]\n",
    "    max_score_broadcast = max_score.view(1, -1).expand(1, vec.size()[1])\n",
    "    return max_score + torch.log(torch.sum(torch.exp(vec - max_score_broadcast)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BiLSTM_CRF(nn.Module):\n",
    "\n",
    "    def __init__(self, vocab_size, tag_to_ix, embedding_dim, hidden_dim):\n",
    "        super(BiLSTM_CRF, self).__init__()\n",
    "        self.embedding_dim = embedding_dim    # word embedding dim\n",
    "        self.hidden_dim = hidden_dim          # Bi-LSTM hidden dim\n",
    "        self.vocab_size = vocab_size          \n",
    "        self.tag_to_ix = tag_to_ix\n",
    "        self.tagset_size = len(tag_to_ix)\n",
    "\n",
    "        self.word_embeds = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim // 2,\n",
    "                            num_layers=1, bidirectional=True)\n",
    "\n",
    "        # 将BiLSTM提取的特征向量映射到特征空间，即经过全连接得到发射分数\n",
    "        self.hidden2tag = nn.Linear(hidden_dim, self.tagset_size)\n",
    "\n",
    "        # 转移矩阵的参数初始化，transitions[i,j]代表的是从第j个tag转移到第i个tag的转移分数\n",
    "        self.transitions = nn.Parameter(\n",
    "            torch.randn(self.tagset_size, self.tagset_size))\n",
    "\n",
    "        # 初始化所有其他tag转移到START_TAG的分数非常小，即不可能由其他tag转移到START_TAG\n",
    "        # 初始化STOP_TAG转移到所有其他tag的分数非常小，即不可能由STOP_TAG转移到其他tag\n",
    "        self.transitions.data[tag_to_ix[START_TAG], :] = -10000\n",
    "        self.transitions.data[:, tag_to_ix[STOP_TAG]] = -10000\n",
    "\n",
    "        self.hidden = self.init_hidden()\n",
    "\n",
    "    def init_hidden(self):\n",
    "        # 初始化LSTM的参数\n",
    "        return (torch.randn(2, 1, self.hidden_dim // 2),\n",
    "                torch.randn(2, 1, self.hidden_dim // 2))\n",
    "    \n",
    "    def _get_lstm_features(self, sentence):\n",
    "        # 通过Bi-LSTM提取特征\n",
    "        self.hidden = self.init_hidden()\n",
    "        embeds = self.word_embeds(sentence).view(len(sentence), 1, -1)\n",
    "        lstm_out, self.hidden = self.lstm(embeds, self.hidden)\n",
    "        lstm_out = lstm_out.view(len(sentence), self.hidden_dim)\n",
    "        lstm_feats = self.hidden2tag(lstm_out)\n",
    "        return lstm_feats\n",
    "    \n",
    "    def _score_sentence(self, feats, tags):\n",
    "        # 计算给定tag序列的分数，即一条路径的分数\n",
    "        score = torch.zeros(1)\n",
    "        tags = torch.cat([torch.tensor([self.tag_to_ix[START_TAG]], dtype=torch.long), tags])\n",
    "        for i, feat in enumerate(feats):\n",
    "            # 递推计算路径分数：转移分数 + 发射分数\n",
    "            score = score + self.transitions[tags[i + 1], tags[i]] + feat[tags[i + 1]]\n",
    "        score = score + self.transitions[self.tag_to_ix[STOP_TAG], tags[-1]]\n",
    "        return score\n",
    "\n",
    "    def _forward_alg(self, feats):\n",
    "        # 通过前向算法递推计算\n",
    "        init_alphas = torch.full((1, self.tagset_size), -10000.)\n",
    "        # 初始化step 0即START位置的发射分数，START_TAG取0其他位置取-10000\n",
    "        init_alphas[0][self.tag_to_ix[START_TAG]] = 0.\n",
    "\n",
    "        # 将初始化START位置为0的发射分数赋值给previous\n",
    "        previous = init_alphas\n",
    "\n",
    "        # 迭代整个句子\n",
    "        for obs in feats:\n",
    "            # 当前时间步的前向tensor\n",
    "            alphas_t = []\n",
    "            for next_tag in range(self.tagset_size):\n",
    "                # 取出当前tag的发射分数，与之前时间步的tag无关\n",
    "                emit_score = obs[next_tag].view(1, -1).expand(1, self.tagset_size)\n",
    "                # 取出当前tag由之前tag转移过来的转移分数\n",
    "                trans_score = self.transitions[next_tag].view(1, -1)\n",
    "                # 当前路径的分数：之前时间步分数 + 转移分数 + 发射分数\n",
    "                next_tag_var = previous + trans_score + emit_score\n",
    "                # 对当前分数取log-sum-exp\n",
    "                alphas_t.append(log_sum_exp(next_tag_var).view(1))\n",
    "            # 更新previous 递推计算下一个时间步\n",
    "            previous = torch.cat(alphas_t).view(1, -1)\n",
    "        # 考虑最终转移到STOP_TAG\n",
    "        terminal_var = previous + self.transitions[self.tag_to_ix[STOP_TAG]]\n",
    "        # 计算最终的分数\n",
    "        scores = log_sum_exp(terminal_var)\n",
    "        return scores\n",
    "\n",
    "\n",
    "    def _viterbi_decode(self, feats):\n",
    "        backpointers = []\n",
    "\n",
    "        # 初始化viterbi的previous变量\n",
    "        init_vvars = torch.full((1, self.tagset_size), -10000.)\n",
    "        init_vvars[0][self.tag_to_ix[START_TAG]] = 0\n",
    "\n",
    "        previous = init_vvars\n",
    "        for obs in feats:\n",
    "            # 保存当前时间步的回溯指针\n",
    "            bptrs_t = []\n",
    "            # 保存当前时间步的viterbi变量\n",
    "            viterbivars_t = []  \n",
    "\n",
    "            for next_tag in range(self.tagset_size):\n",
    "                # 维特比算法记录最优路径时只考虑上一步的分数以及上一步tag转移到当前tag的转移分数\n",
    "                # 并不取决与当前tag的发射分数\n",
    "                next_tag_var = previous + self.transitions[next_tag]\n",
    "                best_tag_id = argmax(next_tag_var)\n",
    "                bptrs_t.append(best_tag_id)\n",
    "                viterbivars_t.append(next_tag_var[0][best_tag_id].view(1))\n",
    "            # 更新previous，加上当前tag的发射分数obs\n",
    "            previous = (torch.cat(viterbivars_t) + obs).view(1, -1)\n",
    "            # 回溯指针记录当前时间步各个tag来源前一步的tag\n",
    "            backpointers.append(bptrs_t)\n",
    "\n",
    "        # Transition to STOP_TAG\n",
    "        # 考虑转移到STOP_TAG的转移分数\n",
    "        terminal_var = previous + self.transitions[self.tag_to_ix[STOP_TAG]]\n",
    "        best_tag_id = argmax(terminal_var)\n",
    "        path_score = terminal_var[0][best_tag_id]\n",
    "\n",
    "        # 通过回溯指针解码出最优路径\n",
    "        best_path = [best_tag_id]\n",
    "        # best_tag_id作为线头，反向遍历backpointers找到最优路径\n",
    "        for bptrs_t in reversed(backpointers):\n",
    "            best_tag_id = bptrs_t[best_tag_id]\n",
    "            best_path.append(best_tag_id)\n",
    "        # 去除START_TAG\n",
    "        start = best_path.pop()\n",
    "        assert start == self.tag_to_ix[START_TAG]  # Sanity check\n",
    "        best_path.reverse()\n",
    "        return path_score, best_path\n",
    "\n",
    "    def neg_log_likelihood(self, sentence, tags):\n",
    "        # CRF损失函数由两部分组成，真实路径的分数和所有路径的总分数。\n",
    "        # 真实路径的分数应该是所有路径中分数最高的。\n",
    "        # log真实路径的分数/log所有可能路径的分数，越大越好，构造crf loss函数取反，loss越小越好\n",
    "        feats = self._get_lstm_features(sentence)\n",
    "        forward_score = self._forward_alg(feats)\n",
    "        gold_score = self._score_sentence(feats, tags)\n",
    "        return forward_score - gold_score\n",
    "\n",
    "    def forward(self, sentence):\n",
    "        # 通过BiLSTM提取发射分数\n",
    "        lstm_feats = self._get_lstm_features(sentence)\n",
    "\n",
    "        # 根据发射分数以及转移分数，通过viterbi解码找到一条最优路径\n",
    "        score, tag_seq = self._viterbi_decode(lstm_feats)\n",
    "        return score, tag_seq\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor(122.0280), [3, 2, 7, 8, 6, 4, 8, 6, 4, 8, 6, 4, 8, 6, 4, 8, 6, 4, 8, 6, 4, 8, 6, 4, 8, 6, 4, 8, 6, 4, 8, 6, 4, 8, 6, 4, 8, 6, 8, 6, 4, 8, 6, 4, 8, 6, 4, 8, 6, 4, 8, 6, 4, 8, 6, 4, 8, 6, 4, 8, 6, 4, 8, 6, 4, 8, 6, 4, 8, 6, 4, 8, 6, 4, 8, 6, 4, 8, 6, 4, 8, 6, 4, 8])\n",
      "the 0  epoch\n",
      "Time Taken: 0 seconds\n",
      "the 1  epoch\n",
      "Time Taken: 6 seconds\n",
      "the 2  epoch\n",
      "Time Taken: 11 seconds\n",
      "the 3  epoch\n",
      "Time Taken: 16 seconds\n",
      "the 4  epoch\n",
      "Time Taken: 21 seconds\n",
      "the 5  epoch\n",
      "Time Taken: 27 seconds\n",
      "the 6  epoch\n",
      "Time Taken: 32 seconds\n",
      "the 7  epoch\n",
      "Time Taken: 37 seconds\n",
      "the 8  epoch\n",
      "Time Taken: 42 seconds\n",
      "the 9  epoch\n",
      "Time Taken: 48 seconds\n",
      "(tensor(129.3629), [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n"
     ]
    }
   ],
   "source": [
    "START_TAG = \"<START>\"\n",
    "STOP_TAG = \"<STOP>\"\n",
    "EMBEDDING_DIM = 11\n",
    "HIDDEN_DIM = 6\n",
    "import time\n",
    "t = time.time()\n",
    "\n",
    "# 将训练集汉字使用数字表示\n",
    "# 为了方便调试，先使用100条数据进行模型训练，选手可以采用全量数据进行训练\n",
    "training_data = training_data_txt[:100] \n",
    "word_to_ix = {}\n",
    "for sentence, tags in training_data:\n",
    "    for word in sentence:\n",
    "        if word not in word_to_ix:\n",
    "            word_to_ix[word] = len(word_to_ix)\n",
    "# 将测试集汉字使用数字表示\n",
    "testing_data = testing_data_txt\n",
    "for sentence in testing_data:\n",
    "    for word in sentence:\n",
    "        if word not in word_to_ix:\n",
    "            word_to_ix[word] = len(word_to_ix)\n",
    "\n",
    "tag_to_ix = { \"O\": 0, \"B-BANK\": 1, \"I-BANK\": 2, \"B-PRODUCT\":3,'I-PRODUCT':4, \n",
    "             'B-COMMENTS_N':5, 'I-COMMENTS_N':6, 'B-COMMENTS_ADJ':7, \n",
    "             'I-COMMENTS_ADJ':8, START_TAG: 9, STOP_TAG: 10}\n",
    "\n",
    "model = BiLSTM_CRF(len(word_to_ix), tag_to_ix, EMBEDDING_DIM, HIDDEN_DIM)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, weight_decay=1e-4)\n",
    "\n",
    "# 训练前检查模型预测结果\n",
    "with torch.no_grad():\n",
    "    precheck_sent = prepare_sequence(training_data[0][0], word_to_ix)\n",
    "    precheck_tags = torch.tensor([tag_to_ix[t] for t in training_data[0][1]], dtype=torch.long)\n",
    "    print(model(precheck_sent))\n",
    "    a = model(precheck_sent)\n",
    "    a = pd.Series(a)\n",
    "# Make sure prepare_sequence from earlier in the LSTM section is loaded\n",
    "for epoch in range(10): \n",
    "    print('the',epoch,' epoch')\n",
    "    print(f'Time Taken: {round(time.time()-t)} seconds')\n",
    "    for sentence, tags in training_data:\n",
    "        # 第一步，pytorch梯度累积，需要清零梯度\n",
    "        model.zero_grad()\n",
    "\n",
    "        # 第二步，将输入转化为tensors\n",
    "        sentence_in = prepare_sequence(sentence, word_to_ix)\n",
    "        targets = torch.tensor([tag_to_ix[t] for t in tags], dtype=torch.long)\n",
    "\n",
    "        # 进行前向计算，取出crf loss\n",
    "        loss = model.neg_log_likelihood(sentence_in, targets)\n",
    "\n",
    "        # 第四步，计算loss，梯度，通过optimier更新参数\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "# 训练结束查看模型预测结果，对比观察模型是否学到\n",
    "with torch.no_grad():\n",
    "    precheck_sent = prepare_sequence(training_data[3][0], word_to_ix)\n",
    "    print(model(precheck_sent))\n",
    "    a = model(precheck_sent)\n",
    "    a = pd.Series(a)\n",
    "    a.to_csv('test1.csv')\n",
    "# We got it!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 任务2：情感分类\n",
    "\n",
    "1. 使用TF-IDF向量化\n",
    "2. 线性回归进行分类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7528\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# X_train = list(train_data['text'])\n",
    "# X_test = list(train_data['text'][800:1000])\n",
    "\n",
    "# y_train = list(train_data['class'])\n",
    "# y_test = list(train_data['class'][800:1000])\n",
    "\n",
    "# test_data_sent = list(test_data['text']) # 列表格式\n",
    "# text_all = X_train + test_data_sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectoriser fitted.\n",
      "No. of feature_words:  44580\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectoriser = TfidfVectorizer(ngram_range=(1,2), max_features=500000)\n",
    "vectoriser.fit(text_all)\n",
    "print(f'Vectoriser fitted.')\n",
    "print('No. of feature_words: ', len(vectoriser.get_feature_names()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Transformed.\n"
     ]
    }
   ],
   "source": [
    "X_train = vectoriser.transform(X_train)\n",
    "test_data_text  = vectoriser.transform(test_data_sent)\n",
    "# X_test  = vectoriser.transform(X_test)\n",
    "print(f'Data Transformed.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=2, max_iter=1000, n_jobs=-1)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "LRmodel = LogisticRegression(C = 2, max_iter = 1000, n_jobs=-1)\n",
    "LRmodel.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "file = open('vectoriser-ngram-(1,2).pickle','wb')\n",
    "pickle.dump(vectoriser, file)\n",
    "file.close()\n",
    "\n",
    "file = open('Sentiment-LR.pickle','wb')\n",
    "pickle.dump(LRmodel, file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>别的卡有钱吗？先救急，用用，</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>没有??我就办一张招行的卡</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>打信用卡客服电话协商吧</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>打银行客服热线转人工客服反映。工行的客服还可以</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>目前3行，4年没提，工商银行的</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>刚拿到卡之后我看预审批更新了，想曲线芭比白，昂被拒了。。。</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>走无卡通道申请二卡，多搞点卡</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>销了重申，额度可能就会高些</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>你可以说一下有哪些行的卡，额度是多少，然后销掉一些，最后去建行网点重新办理一张信用卡。</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>除了申请大白卡，小建基本没有靠申卡曲线提额的可能。</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            text  class\n",
       "0                                 别的卡有钱吗？先救急，用用，      2\n",
       "1                                  没有??我就办一张招行的卡      2\n",
       "2                                    打信用卡客服电话协商吧      2\n",
       "3                        打银行客服热线转人工客服反映。工行的客服还可以      2\n",
       "4                                目前3行，4年没提，工商银行的      2\n",
       "..                                           ...    ...\n",
       "195                刚拿到卡之后我看预审批更新了，想曲线芭比白，昂被拒了。。。      2\n",
       "196                               走无卡通道申请二卡，多搞点卡      2\n",
       "197                                销了重申，额度可能就会高些      2\n",
       "198  你可以说一下有哪些行的卡，额度是多少，然后销掉一些，最后去建行网点重新办理一张信用卡。      2\n",
       "199                    除了申请大白卡，小建基本没有靠申卡曲线提额的可能。      2\n",
       "\n",
       "[200 rows x 2 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def load_models():\n",
    "    '''\n",
    "    Replace '..path/' by the path of the saved models.\n",
    "    '''\n",
    "    \n",
    "    # Load the vectoriser.\n",
    "    file = open('./vectoriser-ngram-(1,2).pickle', 'rb')\n",
    "    vectoriser = pickle.load(file)\n",
    "    file.close()\n",
    "    # Load the LR Model.\n",
    "    file = open('./Sentiment-LR.pickle', 'rb')\n",
    "    LRmodel = pickle.load(file)\n",
    "    file.close()\n",
    "    \n",
    "    return vectoriser, LRmodel\n",
    "\n",
    "def predict(vectoriser, model, text):\n",
    "    # Predict the sentiment\n",
    "    textdata = vectoriser.transform(text)\n",
    "    sentiment = model.predict(textdata)\n",
    "    \n",
    "    # Make a list of text with sentiment.\n",
    "    data = []\n",
    "    for text, pred in zip(text, sentiment):\n",
    "        data.append((text,pred))\n",
    "        \n",
    "    # Convert the list into a Pandas DataFrame.\n",
    "    df = pd.DataFrame(data, columns = ['text','class'])\n",
    "    return df\n",
    "\n",
    "sentiment_result = predict(vectoriser, LRmodel, X_test)\n",
    "sentiment_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 生成提交文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>共享一个额度，没啥必要，四个卡不要年费吗？你这种人头，银行最喜欢，广发是出了名的风控严，套现...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>炸了，就2000.浦发没那么好心，草</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>挂了电话自己打过去分期提额可以少分一点的</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>比如你首卡10k，二卡也10k，信报上显示邮政总共给你的授信额度是20k</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>3000吗，浦发总是这样</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2878</th>\n",
       "      <td>2878</td>\n",
       "      <td>除非你同意，不然不会自动分期的啊</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2879</th>\n",
       "      <td>2879</td>\n",
       "      <td>还是你厉害，我在办卡过程中就被客服气完了。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2880</th>\n",
       "      <td>2880</td>\n",
       "      <td>有些卡就是自动分期的，手机上申请都会注明</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2881</th>\n",
       "      <td>2881</td>\n",
       "      <td>我信用卡额度3万，我去年还清了一次了，现在告诉我欠6万，我万念俱灰</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2882</th>\n",
       "      <td>2882</td>\n",
       "      <td>备用金你没用也要还吗</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2883 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                               text\n",
       "0        0  共享一个额度，没啥必要，四个卡不要年费吗？你这种人头，银行最喜欢，广发是出了名的风控严，套现...\n",
       "1        1                                 炸了，就2000.浦发没那么好心，草\n",
       "2        2                               挂了电话自己打过去分期提额可以少分一点的\n",
       "3        3               比如你首卡10k，二卡也10k，信报上显示邮政总共给你的授信额度是20k\n",
       "4        4                                       3000吗，浦发总是这样\n",
       "...    ...                                                ...\n",
       "2878  2878                                   除非你同意，不然不会自动分期的啊\n",
       "2879  2879                              还是你厉害，我在办卡过程中就被客服气完了。\n",
       "2880  2880                               有些卡就是自动分期的，手机上申请都会注明\n",
       "2881  2881                  我信用卡额度3万，我去年还清了一次了，现在告诉我欠6万，我万念俱灰\n",
       "2882  2882                                         备用金你没用也要还吗\n",
       "\n",
       "[2883 rows x 2 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = pd.read_csv('./test_public.csv')\n",
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "ix_to_tag = dict([v,k] for k, v in tag_to_ix.items())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 在test数据集预测结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 实体识别结果\n",
    "result = []\n",
    "with torch.no_grad():\n",
    "    for i in range(len(test_data)):\n",
    "        precheck_sent = prepare_sequence(test_data.iloc[i][1], word_to_ix)\n",
    "        sig_res = model(precheck_sent)[1]\n",
    "        for i in range(len(sig_res)):\n",
    "            sig_res[i] = ix_to_tag[sig_res[i]]\n",
    "        result.append(' '.join(sig_res))\n",
    "test_data['BIO_anno'] = result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['B-COMMENTS_N I-COMMENTS_N O O B-COMMENTS_N I-COMMENTS_N O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O',\n",
       " 'O O O O O O O O O O O O O O O O O O',\n",
       " 'O O O O O O O O O O O B-COMMENTS_N I-COMMENTS_N O O O O O O O',\n",
       " 'O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O B-COMMENTS_N I-COMMENTS_N O O O O',\n",
       " 'O O O O O O O O O O O O',\n",
       " 'O O O O O O O O O O O O O O O O O O O O O O',\n",
       " 'O O O O O O O O O O O O O O O O',\n",
       " 'O O O O O O O O O O O O O O O B-COMMENTS_N I-COMMENTS_N O',\n",
       " 'O O O O O O O O O O O B-COMMENTS_N I-COMMENTS_N O O O O O',\n",
       " 'O O O O O O O O O O O O O']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 预测test data 的sentiment 分类\n",
    "sentiment_result = predict(vectoriser, LRmodel, test_data_sent)\n",
    "test_data['class'] = list(sentiment_result['class'])\n",
    "test_data.to_csv('test_baseline.csv', index = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       2\n",
      "1       2\n",
      "2       2\n",
      "3       2\n",
      "4       2\n",
      "       ..\n",
      "2878    2\n",
      "2879    2\n",
      "2880    2\n",
      "2881    2\n",
      "2882    2\n",
      "Name: class, Length: 2883, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(test_data['class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
