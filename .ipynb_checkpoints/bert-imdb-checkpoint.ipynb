{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2021-08-03T09:19:08.328728Z",
     "iopub.status.busy": "2021-08-03T09:19:08.328308Z",
     "iopub.status.idle": "2021-08-03T09:19:08.338546Z",
     "shell.execute_reply": "2021-08-03T09:19:08.337436Z",
     "shell.execute_reply.started": "2021-08-03T09:19:08.328629Z"
    }
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "# for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "#     for filename in filenames:\n",
    "#         print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-03T09:19:08.341228Z",
     "iopub.status.busy": "2021-08-03T09:19:08.340514Z",
     "iopub.status.idle": "2021-08-03T09:19:08.803627Z",
     "shell.execute_reply": "2021-08-03T09:19:08.802465Z",
     "shell.execute_reply.started": "2021-08-03T09:19:08.341139Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import os\n",
    "%cd / "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-03T09:19:08.805929Z",
     "iopub.status.busy": "2021-08-03T09:19:08.805512Z",
     "iopub.status.idle": "2021-08-03T09:20:28.228987Z",
     "shell.execute_reply": "2021-08-03T09:20:28.227963Z",
     "shell.execute_reply.started": "2021-08-03T09:19:08.805884Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/acllmdb/aclImdb/train/pos\n",
      "/kaggle/input/acllmdb/aclImdb/train/neg\n",
      "/kaggle/input/acllmdb/aclImdb/test/pos\n",
      "/kaggle/input/acllmdb/aclImdb/test/neg\n"
     ]
    }
   ],
   "source": [
    "def load_dataset(paths):\n",
    "    data = []\n",
    "    label = []\n",
    "    value = 0\n",
    "    for path in paths:\n",
    "        print(path)\n",
    "        if path.split('/')[-1] == 'pos':\n",
    "            value = 1\n",
    "        else:\n",
    "            value = 0\n",
    "        for son in os.listdir(path):\n",
    "            new_path = os.path.join(path,son)\n",
    "            with open(new_path,'r') as f:\n",
    "                lines = f.readlines()\n",
    "                for line in lines:\n",
    "                    data.append(line)\n",
    "                    label.append(value)\n",
    "    return data,label\n",
    "train_data,train_label = load_dataset(['/kaggle/input/acllmdb/aclImdb/train/pos','/kaggle/input/acllmdb/aclImdb/train/neg'])#'/kaggle/input/acllmdb/aclImdb/train/neg'\n",
    "test_data,test_label = load_dataset(['/kaggle/input/acllmdb/aclImdb/test/pos','/kaggle/input/acllmdb/aclImdb/test/neg'])#,'/kaggle/input/acllmdb/aclImdb/test/neg'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-03T09:20:28.230876Z",
     "iopub.status.busy": "2021-08-03T09:20:28.230466Z",
     "iopub.status.idle": "2021-08-03T09:20:34.591847Z",
     "shell.execute_reply": "2021-08-03T09:20:34.590829Z",
     "shell.execute_reply.started": "2021-08-03T09:20:28.230832Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "# !pip install transformers\n",
    "from transformers import BertTokenizer, BertModel\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "bertmodel = BertModel.from_pretrained('bert-base-uncased')\n",
    "# ret = tokenizer.tokenize('what are you doing now')\n",
    "# input_ids = tokenizer.convert_tokens_to_ids(ret)\n",
    "# inputs = tokenizer.encode('Hello, my dog is cute',max_length = 3)\n",
    "# inputssss = tokenizer('Hello, my dog is cute',max_length = 512)\n",
    "# print(inputssss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-03T09:20:34.593697Z",
     "iopub.status.busy": "2021-08-03T09:20:34.593278Z",
     "iopub.status.idle": "2021-08-03T09:20:34.600815Z",
     "shell.execute_reply": "2021-08-03T09:20:34.596998Z",
     "shell.execute_reply.started": "2021-08-03T09:20:34.593664Z"
    }
   },
   "outputs": [],
   "source": [
    "# for name,para in model.named_parameters():\n",
    "#     print(name,':',para)\n",
    "# print(model.config.hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-03T09:20:34.603013Z",
     "iopub.status.busy": "2021-08-03T09:20:34.602502Z",
     "iopub.status.idle": "2021-08-03T09:20:37.368268Z",
     "shell.execute_reply": "2021-08-03T09:20:37.367422Z",
     "shell.execute_reply.started": "2021-08-03T09:20:34.602968Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "class myModel(torch.nn.Module):\n",
    "    def __init__(self,bertmodel,dropout=None):\n",
    "        super(myModel,self).__init__()\n",
    "        self.bertmodel = bertmodel\n",
    "        self.dropout = nn.Dropout(dropout if dropout is not None else 0.1)\n",
    "        # 语义匹配任务: 相似、不相似 2 分类任务\n",
    "        self.classifier = nn.Linear(self.bertmodel.config.hidden_size, 2)\n",
    "    def forward(self,input_ids,token_type_ids,attention_mask):\n",
    "        outputs= self.bertmodel(input_ids,token_type_ids = token_type_ids, attention_mask=attention_mask)#\n",
    "        outputs = outputs.pooler_output\n",
    "        outputs = self.dropout(outputs)\n",
    "        # 基于文本对的语义表示向量进行 2 分类任务\n",
    "        logits = self.classifier(outputs)\n",
    "        return logits\n",
    "model = myModel(bertmodel)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-03T09:20:37.369977Z",
     "iopub.status.busy": "2021-08-03T09:20:37.369612Z",
     "iopub.status.idle": "2021-08-03T09:20:37.373821Z",
     "shell.execute_reply": "2021-08-03T09:20:37.372890Z",
     "shell.execute_reply.started": "2021-08-03T09:20:37.369940Z"
    }
   },
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# def convert_examples_to_feature(examples,tokenizer =tokenizer,max_length = 512):\n",
    "#     data = []\n",
    "#     for text in examples:\n",
    "#         encoder_inputs = tokenizer(text,max_length)\n",
    "#         input_ids = encoder_inputs['input_ids']\n",
    "#         data.append(input_ids)\n",
    "#     return data\n",
    "\n",
    "# train_data = convert_examples_to_feature(train_data)\n",
    "# test_data = convert_examples_to_feature(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-03T09:20:37.378209Z",
     "iopub.status.busy": "2021-08-03T09:20:37.377822Z",
     "iopub.status.idle": "2021-08-03T09:20:37.387971Z",
     "shell.execute_reply": "2021-08-03T09:20:37.387030Z",
     "shell.execute_reply.started": "2021-08-03T09:20:37.378176Z"
    }
   },
   "outputs": [],
   "source": [
    "# print(len(train_data))\n",
    "# print(train_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-03T09:20:37.390231Z",
     "iopub.status.busy": "2021-08-03T09:20:37.389857Z",
     "iopub.status.idle": "2021-08-03T09:26:50.728610Z",
     "shell.execute_reply": "2021-08-03T09:26:50.727752Z",
     "shell.execute_reply.started": "2021-08-03T09:20:37.390194Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import Dataset\n",
    "class myDataset(Dataset):\n",
    "    def __init__(self,data,label):\n",
    "        super(myDataset).__init__()\n",
    "        self.input_ids = []\n",
    "        self.token_type_ids = []\n",
    "        self.attention_mask = []\n",
    "        self.label = label\n",
    "        for text in data:\n",
    "            encoder_inputs = tokenizer(text,max_length = 128)\n",
    "            self.input_ids.append(encoder_inputs['input_ids'])\n",
    "            self.token_type_ids.append(encoder_inputs['token_type_ids'])\n",
    "            self.attention_mask.append(encoder_inputs['attention_mask'])\n",
    "    def __getitem__(self,idx):\n",
    "        input_ids = self.input_ids[idx]\n",
    "        token_type_ids = self.token_type_ids[idx]\n",
    "        attention_mask = self.attention_mask[idx]\n",
    "        label = self.label[idx]\n",
    "        return torch.tensor(input_ids, dtype=torch.long),torch.tensor(token_type_ids, dtype=torch.long),torch.tensor(attention_mask, dtype=torch.long),torch.tensor(label, dtype=torch.long)\n",
    "    def __len__(self):\n",
    "        return len(self.input_ids)\n",
    "train_dataset = myDataset(train_data,train_label)\n",
    "test_dataset = myDataset(test_data,test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-03T09:26:50.730437Z",
     "iopub.status.busy": "2021-08-03T09:26:50.730084Z",
     "iopub.status.idle": "2021-08-03T09:26:50.742288Z",
     "shell.execute_reply": "2021-08-03T09:26:50.741348Z",
     "shell.execute_reply.started": "2021-08-03T09:26:50.730389Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def my_collate_fn(data):\n",
    "    new_input_ids = []\n",
    "    new_token_type_ids = []\n",
    "    new_attention_mask = []\n",
    "    new_y = []\n",
    "    max_length = 0\n",
    "    for input_ids,token_type_ids,attention_mask,label in data:\n",
    "        token_length = len(input_ids)\n",
    "        max_length = max(max_length,token_length)\n",
    "    if max_length > 512:\n",
    "        max_length = 512\n",
    "    for input_ids,token_type_ids,attention_mask,label in data:\n",
    "        token_length = len(input_ids)\n",
    "        input_ids = np.array(input_ids)\n",
    "        token_type_ids = np.array(token_type_ids)\n",
    "        attention_mask = np.array(attention_mask)\n",
    "#         label = np.array(label)   因为这里取出的label就是一个tensor（1），其里面是一个int整数，如果转成np.array，后面再转tensor就会报no len（）错，错误描述可以看下一个cell\n",
    "        if token_length < max_length:\n",
    "            input_ids = np.concatenate([input_ids[:-1],[tokenizer.pad_token_id] * (max_length - token_length) + [tokenizer.sep_token_id]],axis = 0)\n",
    "            token_type_ids = np.array(token_type_ids)\n",
    "            token_type_ids = np.concatenate([token_type_ids,[0] * (max_length - token_length)],axis = 0)\n",
    "            attention_mask = np.array(attention_mask)\n",
    "            attention_mask = np.concatenate([attention_mask,[0]* (max_length - token_length)],axis = 0)\n",
    "        new_input_ids.append(input_ids)\n",
    "        new_token_type_ids.append(token_type_ids)\n",
    "        new_attention_mask.append(attention_mask)\n",
    "        new_y.append(label)\n",
    "    new_input_ids = torch.tensor(new_input_ids,dtype=torch.long)\n",
    "    new_token_type_ids = torch.tensor(new_token_type_ids,dtype=torch.long)\n",
    "    new_attention_mask = torch.tensor(new_attention_mask,dtype=torch.long)\n",
    "    new_y = torch.tensor(new_y,dtype=torch.long)\n",
    "    return new_input_ids, new_token_type_ids,new_attention_mask,new_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-03T09:26:50.744282Z",
     "iopub.status.busy": "2021-08-03T09:26:50.743615Z",
     "iopub.status.idle": "2021-08-03T09:26:50.754197Z",
     "shell.execute_reply": "2021-08-03T09:26:50.753357Z",
     "shell.execute_reply.started": "2021-08-03T09:26:50.744244Z"
    }
   },
   "outputs": [],
   "source": [
    "# a = torch.tensor(1)\n",
    "# b = torch.tensor(2)\n",
    "# c = np.array(a)\n",
    "# d = np.array(b)\n",
    "# e = [c,d]\n",
    "# print(torch.tensor(e))\n",
    "# TypeError: len() of unsized object  会报这个错是因为 a中值是一个int型，其没有len（）函数，而在转tensor时，会调取其len（）,故报错，因此上面的label不能转成np.ndarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-03T09:26:50.755961Z",
     "iopub.status.busy": "2021-08-03T09:26:50.755595Z",
     "iopub.status.idle": "2021-08-03T09:26:50.770749Z",
     "shell.execute_reply": "2021-08-03T09:26:50.769514Z",
     "shell.execute_reply.started": "2021-08-03T09:26:50.755926Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "print(len(train_dataset))\n",
    "train_dataset, valid_dataset = torch.utils.data.random_split(train_dataset, [20000, 5000])\n",
    "train_data_loader = DataLoader(\n",
    "                train_dataset,\n",
    "                batch_size = 64,\n",
    "                collate_fn = my_collate_fn,\n",
    "                shuffle=True\n",
    ")\n",
    "valid_data_loader = DataLoader(\n",
    "                valid_dataset,\n",
    "                batch_size = 64,\n",
    "                collate_fn = my_collate_fn,\n",
    "                shuffle=True\n",
    ")\n",
    "test_data_loader = DataLoader(\n",
    "                test_dataset,\n",
    "                batch_size = 32,\n",
    "                shuffle=True,\n",
    "                collate_fn = my_collate_fn\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-03T09:26:50.772764Z",
     "iopub.status.busy": "2021-08-03T09:26:50.772311Z",
     "iopub.status.idle": "2021-08-03T09:26:50.980639Z",
     "shell.execute_reply": "2021-08-03T09:26:50.979604Z",
     "shell.execute_reply.started": "2021-08-03T09:26:50.772707Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.499\n"
     ]
    }
   ],
   "source": [
    "count = 0 \n",
    "for batch in valid_dataset:\n",
    "    if batch[-1] == 0:\n",
    "        count += 1\n",
    "print(count / 5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-03T09:26:50.982868Z",
     "iopub.status.busy": "2021-08-03T09:26:50.982237Z",
     "iopub.status.idle": "2021-08-03T09:26:51.582213Z",
     "shell.execute_reply": "2021-08-03T09:26:51.581160Z",
     "shell.execute_reply.started": "2021-08-03T09:26:50.982822Z"
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "from torch.optim import lr_scheduler\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "criterion = criterion.to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "scheduler = lr_scheduler.MultiStepLR(optimizer,milestones=[20,80],gamma = 0.9)\n",
    "epochs = 5\n",
    "# !pip install torchmetrics\n",
    "import torchmetrics as metrics\n",
    "train_accuracy = metrics.Accuracy()\n",
    "train_accuracy.to(device)\n",
    "ckpt_dir = './'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-03T09:26:51.584211Z",
     "iopub.status.busy": "2021-08-03T09:26:51.583777Z",
     "iopub.status.idle": "2021-08-03T09:26:51.588145Z",
     "shell.execute_reply": "2021-08-03T09:26:51.587169Z",
     "shell.execute_reply.started": "2021-08-03T09:26:51.584158Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-03T09:26:51.590415Z",
     "iopub.status.busy": "2021-08-03T09:26:51.589797Z",
     "iopub.status.idle": "2021-08-03T09:47:37.618996Z",
     "shell.execute_reply": "2021-08-03T09:47:37.618094Z",
     "shell.execute_reply.started": "2021-08-03T09:26:51.590358Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 30, epoch: 1, batch: 30, loss: 0.30070, accu: 0.90625, speed: 0.45 step/s\n",
      "global step 60, epoch: 1, batch: 60, loss: 0.28492, accu: 0.90625, speed: 0.46 step/s\n",
      "global step 90, epoch: 1, batch: 90, loss: 0.34072, accu: 0.82812, speed: 0.46 step/s\n",
      "global step 120, epoch: 1, batch: 120, loss: 0.31917, accu: 0.89062, speed: 0.46 step/s\n",
      "global step 150, epoch: 1, batch: 150, loss: 0.22120, accu: 0.90625, speed: 0.46 step/s\n",
      "global step 180, epoch: 1, batch: 180, loss: 0.33422, accu: 0.85938, speed: 0.46 step/s\n",
      "global step 210, epoch: 1, batch: 210, loss: 0.30382, accu: 0.85938, speed: 0.46 step/s\n",
      "global step 240, epoch: 1, batch: 240, loss: 0.24825, accu: 0.89062, speed: 0.46 step/s\n",
      "global step 270, epoch: 1, batch: 270, loss: 0.28896, accu: 0.82812, speed: 0.46 step/s\n",
      "global step 300, epoch: 1, batch: 300, loss: 0.41404, accu: 0.85938, speed: 0.46 step/s\n",
      "epoch:1,total_loss:0.35324,accu:0.83865\n",
      "eval_acc: 0.86980 \n",
      "global step 330, epoch: 2, batch: 17, loss: 0.27429, accu: 0.89062, speed: 0.23 step/s\n",
      "global step 360, epoch: 2, batch: 47, loss: 0.11035, accu: 0.96875, speed: 0.46 step/s\n",
      "global step 390, epoch: 2, batch: 77, loss: 0.07958, accu: 0.98438, speed: 0.46 step/s\n",
      "global step 420, epoch: 2, batch: 107, loss: 0.22327, accu: 0.93750, speed: 0.46 step/s\n",
      "global step 450, epoch: 2, batch: 137, loss: 0.35760, accu: 0.85938, speed: 0.46 step/s\n",
      "global step 480, epoch: 2, batch: 167, loss: 0.23188, accu: 0.93750, speed: 0.46 step/s\n",
      "global step 510, epoch: 2, batch: 197, loss: 0.12432, accu: 0.96875, speed: 0.46 step/s\n",
      "global step 540, epoch: 2, batch: 227, loss: 0.15646, accu: 0.92188, speed: 0.46 step/s\n",
      "global step 570, epoch: 2, batch: 257, loss: 0.14733, accu: 0.95312, speed: 0.46 step/s\n",
      "global step 600, epoch: 2, batch: 287, loss: 0.13946, accu: 0.96875, speed: 0.46 step/s\n",
      "epoch:2,total_loss:0.20175,accu:0.88003\n",
      "eval_acc: 0.85680 \n",
      "global step 630, epoch: 3, batch: 4, loss: 0.02362, accu: 1.00000, speed: 0.23 step/s\n",
      "global step 660, epoch: 3, batch: 34, loss: 0.11228, accu: 0.96875, speed: 0.45 step/s\n",
      "global step 690, epoch: 3, batch: 64, loss: 0.19188, accu: 0.92188, speed: 0.46 step/s\n",
      "global step 720, epoch: 3, batch: 94, loss: 0.07411, accu: 0.95312, speed: 0.46 step/s\n",
      "global step 750, epoch: 3, batch: 124, loss: 0.02254, accu: 1.00000, speed: 0.46 step/s\n",
      "global step 780, epoch: 3, batch: 154, loss: 0.09569, accu: 0.95312, speed: 0.46 step/s\n",
      "global step 810, epoch: 3, batch: 184, loss: 0.05387, accu: 0.98438, speed: 0.46 step/s\n",
      "global step 840, epoch: 3, batch: 214, loss: 0.09059, accu: 0.96875, speed: 0.46 step/s\n",
      "global step 870, epoch: 3, batch: 244, loss: 0.11632, accu: 0.95312, speed: 0.46 step/s\n",
      "global step 900, epoch: 3, batch: 274, loss: 0.11151, accu: 0.95312, speed: 0.46 step/s\n",
      "global step 930, epoch: 3, batch: 304, loss: 0.09381, accu: 0.96875, speed: 0.46 step/s\n",
      "epoch:3,total_loss:0.09734,accu:0.90783\n",
      "eval_acc: 0.87260 \n",
      "global step 960, epoch: 4, batch: 21, loss: 0.02967, accu: 0.98438, speed: 0.23 step/s\n",
      "global step 990, epoch: 4, batch: 51, loss: 0.17617, accu: 0.96875, speed: 0.46 step/s\n",
      "global step 1020, epoch: 4, batch: 81, loss: 0.01692, accu: 1.00000, speed: 0.46 step/s\n",
      "global step 1050, epoch: 4, batch: 111, loss: 0.02760, accu: 1.00000, speed: 0.46 step/s\n",
      "global step 1080, epoch: 4, batch: 141, loss: 0.05569, accu: 0.98438, speed: 0.46 step/s\n",
      "global step 1110, epoch: 4, batch: 171, loss: 0.17499, accu: 0.90625, speed: 0.46 step/s\n",
      "global step 1140, epoch: 4, batch: 201, loss: 0.04704, accu: 0.98438, speed: 0.46 step/s\n",
      "global step 1170, epoch: 4, batch: 231, loss: 0.06340, accu: 0.95312, speed: 0.46 step/s\n",
      "global step 1200, epoch: 4, batch: 261, loss: 0.01554, accu: 0.98438, speed: 0.46 step/s\n",
      "global step 1230, epoch: 4, batch: 291, loss: 0.03001, accu: 0.98438, speed: 0.46 step/s\n",
      "epoch:4,total_loss:0.05630,accu:0.92581\n",
      "eval_acc: 0.87220 \n",
      "global step 1260, epoch: 5, batch: 8, loss: 0.02981, accu: 0.98438, speed: 0.23 step/s\n",
      "global step 1290, epoch: 5, batch: 38, loss: 0.00780, accu: 1.00000, speed: 0.46 step/s\n",
      "global step 1320, epoch: 5, batch: 68, loss: 0.02140, accu: 0.98438, speed: 0.46 step/s\n",
      "global step 1350, epoch: 5, batch: 98, loss: 0.14746, accu: 0.96875, speed: 0.46 step/s\n",
      "global step 1380, epoch: 5, batch: 128, loss: 0.04021, accu: 0.98438, speed: 0.46 step/s\n",
      "global step 1410, epoch: 5, batch: 158, loss: 0.14581, accu: 0.98438, speed: 0.46 step/s\n",
      "global step 1440, epoch: 5, batch: 188, loss: 0.03123, accu: 1.00000, speed: 0.46 step/s\n",
      "global step 1470, epoch: 5, batch: 218, loss: 0.14082, accu: 0.93750, speed: 0.46 step/s\n",
      "global step 1500, epoch: 5, batch: 248, loss: 0.03275, accu: 1.00000, speed: 0.46 step/s\n",
      "global step 1530, epoch: 5, batch: 278, loss: 0.00883, accu: 1.00000, speed: 0.46 step/s\n",
      "global step 1560, epoch: 5, batch: 308, loss: 0.02537, accu: 1.00000, speed: 0.46 step/s\n",
      "epoch:5,total_loss:0.03944,accu:0.93806\n",
      "eval_acc: 0.87440 \n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "global_step = 0\n",
    "tic_train = time.time()\n",
    "model.train()\n",
    "for epoch in range(1, epochs + 1):\n",
    "    train_loss = 0\n",
    "    for step, batch in enumerate(train_data_loader, start=1):\n",
    "        optimizer.zero_grad()\n",
    "        input_ids,token_type_ids,attention_mask,labels = batch\n",
    "        input_ids = input_ids.to(device,dtype=torch.long)\n",
    "        token_type_ids = token_type_ids.to(device,dtype=torch.long)\n",
    "        attention_mask =attention_mask.to(device,dtype=torch.long)\n",
    "        labels = labels.to(device,dtype=torch.long)\n",
    "        # 喂数据给model\n",
    "        probs = model(input_ids = input_ids, token_type_ids = token_type_ids, attention_mask = attention_mask)\n",
    "        # 计算损失函数值\n",
    "        loss = criterion(probs, labels)\n",
    "        train_loss += loss\n",
    "        loss.backward()\n",
    "#         for name, parms in model.named_parameters():\n",
    "# #             print(parms.data)\n",
    "#             print('-->name:', name, '-->grad_requirs:', parms.requires_grad, '--weight', torch.mean(parms.data), ' -->grad_value:', torch.mean(parms.grad))\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        # 预测分类概率值\n",
    "        # 计算acc\n",
    "        batch_acc = train_accuracy(probs, labels)\n",
    "        global_step += 1\n",
    "        if global_step % 30 == 0:\n",
    "#             acc = train_accuracy.compute()\n",
    "            print(\n",
    "                \"global step %d, epoch: %d, batch: %d, loss: %.5f, accu: %.5f, speed: %.2f step/s\"\n",
    "                % (global_step, epoch, step, loss, batch_acc,\n",
    "                    10 / (time.time() - tic_train)))\n",
    "            tic_train = time.time()\n",
    "        \n",
    "    print('epoch:%d,total_loss:%.5f,accu:%.5f' %(epoch,train_loss * epoch / global_step, train_accuracy.compute()))\n",
    "    \n",
    "    # 评估当前训练的模型  \n",
    "    save_dir = os.path.join(ckpt_dir, \"model_%d\" % global_step)\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir) \n",
    "    with torch.no_grad():\n",
    "        torch.cuda.empty_cache()\n",
    "        valid_accuracy = metrics.Accuracy()\n",
    "        valid_accuracy.to(device)\n",
    "        for  i, batch in enumerate(valid_data_loader):\n",
    "            input_ids,token_type_ids,attention_mask,labels = batch\n",
    "            input_ids = input_ids.to(device,dtype=torch.long)\n",
    "            token_type_ids = token_type_ids.to(device,dtype=torch.long)\n",
    "            attention_mask =attention_mask.to(device,dtype=torch.long)\n",
    "            labels = labels.to(device,dtype=torch.long)\n",
    "            probs = model(input_ids = input_ids, token_type_ids = token_type_ids, attention_mask = attention_mask)\n",
    "            valid_accuracy(probs,labels)\n",
    "        acc = valid_accuracy.compute()\n",
    "        print('eval_acc: %.5f ' % acc)\n",
    "        torch.save(model.state_dict(),os.path.join(save_dir,'model.pt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-03T09:47:37.620969Z",
     "iopub.status.busy": "2021-08-03T09:47:37.620554Z",
     "iopub.status.idle": "2021-08-03T09:47:37.625490Z",
     "shell.execute_reply": "2021-08-03T09:47:37.624153Z",
     "shell.execute_reply.started": "2021-08-03T09:47:37.620897Z"
    }
   },
   "outputs": [],
   "source": [
    "# save_dir = os.path.join(ckpt_dir, \"model_%d\" % 20)\n",
    "# if not os.path.exists(save_dir):\n",
    "#     os.makedirs(save_dir)\n",
    "# torch.save(model.state_dict(),os.path.join(save_dir,'model.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-03T09:47:37.627606Z",
     "iopub.status.busy": "2021-08-03T09:47:37.627001Z",
     "iopub.status.idle": "2021-08-03T09:49:19.085667Z",
     "shell.execute_reply": "2021-08-03T09:49:19.084629Z",
     "shell.execute_reply.started": "2021-08-03T09:47:37.627567Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval-> step:100,batch_acc:1.00000\n",
      "eval-> step:200,batch_acc:0.84375\n",
      "eval-> step:300,batch_acc:0.84375\n",
      "eval-> step:400,batch_acc:0.90625\n",
      "eval-> step:500,batch_acc:0.84375\n",
      "eval-> step:600,batch_acc:0.87500\n",
      "eval-> step:700,batch_acc:0.93750\n",
      "!!!!eval-> total_acc:0.87148\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "torch.cuda.empty_cache()\n",
    "test_accuracy = metrics.Accuracy()\n",
    "test_accuracy.to(device)\n",
    "for step,batch in enumerate(test_data_loader):\n",
    "    input_ids,token_type_ids,attention_mask,labels = batch\n",
    "    input_ids = input_ids.to(device,dtype=torch.long)\n",
    "    token_type_ids = token_type_ids.to(device,dtype=torch.long)\n",
    "    attention_mask =attention_mask.to(device,dtype=torch.long)\n",
    "    labels = labels.to(device,dtype=torch.long)\n",
    "    probs = model(input_ids = input_ids, token_type_ids = token_type_ids, attention_mask = attention_mask)\n",
    "    batch_acc = test_accuracy(probs, labels)\n",
    "    if step != 0 and step % 100 == 0: \n",
    "        print(\"eval-> step:%d,batch_acc:%.5f\" % (step,batch_acc))\n",
    "print('!!!!eval-> total_acc:%.5f' % test_accuracy.compute())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-03T09:49:19.087548Z",
     "iopub.status.busy": "2021-08-03T09:49:19.087182Z",
     "iopub.status.idle": "2021-08-03T09:49:19.091802Z",
     "shell.execute_reply": "2021-08-03T09:49:19.090573Z",
     "shell.execute_reply.started": "2021-08-03T09:49:19.087509Z"
    }
   },
   "outputs": [],
   "source": [
    "# from transformers import BertTokenizer, BertModel\n",
    "# import torch\n",
    "\n",
    "# tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "# model = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# inputs = tokenizer(\"Hello, my dog is cute\", return_tensors=\"pt\")\n",
    "# outputs = model(**inputs)\n",
    "# last_hidden_states = outputs.pooler_output\n",
    "# print(last_hidden_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-03T09:49:19.093652Z",
     "iopub.status.busy": "2021-08-03T09:49:19.093286Z",
     "iopub.status.idle": "2021-08-03T09:49:19.103188Z",
     "shell.execute_reply": "2021-08-03T09:49:19.102306Z",
     "shell.execute_reply.started": "2021-08-03T09:49:19.093617Z"
    }
   },
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# import numpy as np\n",
    "# from torch.utils.data import Dataset\n",
    "# from torch.utils.data import DataLoader\n",
    "# class myDataset(Dataset):\n",
    "#     def __init__(self,data,label):\n",
    "#         super(myDataset).__init__()\n",
    "#         self.input_ids = data\n",
    "#         self.label = label\n",
    "#     def __getitem__(self,idx):\n",
    "#         return torch.tensor(self.input_ids[idx], dtype=torch.float),torch.tensor(self.label[idx], dtype=torch.float)\n",
    "#     def __len__(self):\n",
    "#         return len(self.input_ids)\n",
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# model = nn.Linear(1, 1)\n",
    "# train_data = np.random.randn(100000).reshape(-1,1)\n",
    "# train_label = np.array(train_data * 2 +1)\n",
    "# test_data = np.random.randn(100000).reshape(-1,1)\n",
    "# test_label = np.array(test_data * 2 +1)\n",
    "# train_dataset = myDataset(train_data,train_label)\n",
    "# test_dataset = myDataset(test_data,test_label)\n",
    "# train_data_loader = DataLoader(\n",
    "#                 train_dataset,\n",
    "#                 batch_size = 16,\n",
    "#                 shuffle=True\n",
    "# )\n",
    "# test_data_loader = DataLoader(\n",
    "#                 test_dataset,\n",
    "#                 batch_size = 16,\n",
    "#                 shuffle=True\n",
    "# )\n",
    "# import torch.nn as nn\n",
    "# from torch import optim \n",
    "# from torch.optim import lr_scheduler\n",
    "# criterion = nn.MSELoss()\n",
    "# criterion = criterion.to(device)\n",
    "# model.to(device)\n",
    "# optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "# scheduler = lr_scheduler.MultiStepLR(optimizer,milestones=[20,80],gamma = 0.9)\n",
    "# epoch = 1\n",
    "# for i in range(1,epoch+1):\n",
    "#     for step,batch in enumerate(train_data_loader):\n",
    "#         inputs,label = batch\n",
    "#         inputs.to(device)\n",
    "#         label.to(device)\n",
    "#         model.to(device)\n",
    "#         print(inputs[0])\n",
    "#         y_hat = model(inputs)\n",
    "#         loss = criterion(y_hat,label)\n",
    "#         optimizer.zero_grad()\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "#         scheduler.step()\n",
    "# model.eval()\n",
    "# print(model(torch.tensor([[0.1],[1.2]])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-03T09:49:19.104839Z",
     "iopub.status.busy": "2021-08-03T09:49:19.104408Z",
     "iopub.status.idle": "2021-08-03T09:49:19.115537Z",
     "shell.execute_reply": "2021-08-03T09:49:19.114708Z",
     "shell.execute_reply.started": "2021-08-03T09:49:19.104801Z"
    }
   },
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import torchmetrics as metrics\n",
    "# class RMSE(metrics.Metric):\n",
    "#     def __init__(self):\n",
    "#         self.add_state(\"sum_squared_errors\",torch.tensor(0),dist_reduce_fx=\"sum\")\n",
    "#         self.add_atate(\"n_observations\",torch.tensor(0),dist_reduce_fx = \"sum\")\n",
    "#     def update(self,preds,target):\n",
    "#         self.sum_squared_errors += torch.sum((pred - target) ** 2)\n",
    "#         self.n_observations += preds.numel()\n",
    "#     def compute(self):\n",
    "#         return torch.sqrt(self.sum_squared_errors / self.n_observations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-03T09:49:19.118965Z",
     "iopub.status.busy": "2021-08-03T09:49:19.117692Z",
     "iopub.status.idle": "2021-08-03T09:49:19.128520Z",
     "shell.execute_reply": "2021-08-03T09:49:19.127680Z",
     "shell.execute_reply.started": "2021-08-03T09:49:19.118936Z"
    }
   },
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import torchmetrics as metrics\n",
    "# train_accuracy = metrics.Accuracy()\n",
    "# # train_accuracy.to(device)\n",
    "# a = np.random.randn(5,10)\n",
    "# b = np.argmax(a,axis = -1)\n",
    "# batch_acc = train_accuracy(torch.tensor(a),torch.tensor(b))\n",
    "# b -= 1\n",
    "# batch_acc = train_accuracy(torch.tensor(a),torch.tensor(b))\n",
    "# acc=train_accuracy.compute()\n",
    "# print(acc) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-03T09:49:19.130198Z",
     "iopub.status.busy": "2021-08-03T09:49:19.129800Z",
     "iopub.status.idle": "2021-08-03T09:49:19.137164Z",
     "shell.execute_reply": "2021-08-03T09:49:19.136452Z",
     "shell.execute_reply.started": "2021-08-03T09:49:19.130160Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
